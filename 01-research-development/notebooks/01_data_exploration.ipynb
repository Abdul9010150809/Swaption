{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration Notebook\n",
    "\n",
    "This notebook explores the financial data used for training pricing models in the Price Matrix system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Import our custom modules\n",
    "from data.data_generator import FinancialDataGenerator\n",
    "from data.preprocessor import FinancialDataPreprocessor\n",
    "from utils.visualization import FinancialVisualizer\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Generation\n",
    "\n",
    "Let's start by generating synthetic financial data for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data generator\n",
    "generator = FinancialDataGenerator(seed=42)\n",
    "\n",
    "# Generate different types of financial data\n",
    "print(\"Generating financial data...\")\n",
    "\n",
    "# Yield curve data\n",
    "yield_curves = generator.generate_yield_curve(n_samples=1000)\n",
    "print(f\"Yield curves shape: {yield_curves.shape}\")\n",
    "\n",
    "# Volatility surface data\n",
    "vol_surfaces = generator.generate_volatility_surface(n_samples=1000)\n",
    "print(f\"Volatility surfaces shape: {vol_surfaces.shape}\")\n",
    "\n",
    "# Option pricing data\n",
    "option_data = generator.generate_option_prices(n_samples=5000)\n",
    "print(f\"Option data shape: {option_data.shape}\")\n",
    "\n",
    "# Swaption data\n",
    "swaption_data = generator.generate_swaption_data(n_samples=2000)\n",
    "print(f\"Swaption data shape: {swaption_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Data Exploration\n",
    "\n",
    "Let's examine the basic statistics and distributions of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic statistics for option data\n",
    "print(\"Option Data Statistics:\")\n",
    "print(option_data.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(option_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distributions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle('Option Data Distributions', fontsize=16)\n",
    "\n",
    "# Spot price distribution\n",
    "axes[0, 0].hist(option_data['spot_price'], bins=50, alpha=0.7)\n",
    "axes[0, 0].set_title('Spot Price Distribution')\n",
    "axes[0, 0].set_xlabel('Spot Price')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Strike price distribution\n",
    "axes[0, 1].hist(option_data['strike_price'], bins=50, alpha=0.7)\n",
    "axes[0, 1].set_title('Strike Price Distribution')\n",
    "axes[0, 1].set_xlabel('Strike Price')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Volatility distribution\n",
    "axes[0, 2].hist(option_data['volatility'], bins=50, alpha=0.7)\n",
    "axes[0, 2].set_title('Volatility Distribution')\n",
    "axes[0, 2].set_xlabel('Volatility')\n",
    "axes[0, 2].set_ylabel('Frequency')\n",
    "\n",
    "# Time to expiry distribution\n",
    "axes[1, 0].hist(option_data['time_to_expiry'], bins=50, alpha=0.7)\n",
    "axes[1, 0].set_title('Time to Expiry Distribution')\n",
    "axes[1, 0].set_xlabel('Time to Expiry (years)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Risk-free rate distribution\n",
    "axes[1, 1].hist(option_data['risk_free_rate'], bins=50, alpha=0.7)\n",
    "axes[1, 1].set_title('Risk-Free Rate Distribution')\n",
    "axes[1, 1].set_xlabel('Risk-Free Rate')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Option price distribution\n",
    "axes[1, 2].hist(option_data['call_price'], bins=50, alpha=0.7, label='Call')\n",
    "axes[1, 2].hist(option_data['put_price'], bins=50, alpha=0.7, label='Put')\n",
    "axes[1, 2].set_title('Option Price Distribution')\n",
    "axes[1, 2].set_xlabel('Option Price')\n",
    "axes[1, 2].set_ylabel('Frequency')\n",
    "axes[1, 2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Correlation Analysis\n",
    "\n",
    "Let's examine the correlations between different variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "correlation_matrix = option_data.corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "plt.title('Correlation Matrix - Option Data')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Moneyness Analysis\n",
    "\n",
    "Let's analyze the relationship between moneyness and option prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create moneyness categories\n",
    "option_data['moneyness_category'] = pd.cut(option_data['moneyness'], \n",
    "                                         bins=[0, 0.8, 0.95, 1.05, 1.2, float('inf')],\n",
    "                                         labels=['Deep ITM', 'ITM', 'ATM', 'OTM', 'Deep OTM'])\n",
    "\n",
    "# Plot average prices by moneyness\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "avg_prices = option_data.groupby('moneyness_category')[['call_price', 'put_price']].mean()\n",
    "avg_prices.plot(kind='bar', ax=plt.gca())\n",
    "plt.title('Average Option Prices by Moneyness')\n",
    "plt.xlabel('Moneyness Category')\n",
    "plt.ylabel('Average Price')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.scatterplot(data=option_data, x='moneyness', y='call_price', alpha=0.6)\n",
    "plt.title('Call Price vs Moneyness')\n",
    "plt.xlabel('Moneyness')\n",
    "plt.ylabel('Call Price')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Volatility Analysis\n",
    "\n",
    "Let's examine the volatility patterns in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot volatility relationships\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Volatility vs time to expiry\n",
    "axes[0, 0].scatter(option_data['time_to_expiry'], option_data['volatility'], alpha=0.6)\n",
    "axes[0, 0].set_xlabel('Time to Expiry (years)')\n",
    "axes[0, 0].set_ylabel('Volatility')\n",
    "axes[0, 0].set_title('Volatility vs Time to Expiry')\n",
    "\n",
    "# Volatility vs moneyness\n",
    "axes[0, 1].scatter(option_data['moneyness'], option_data['volatility'], alpha=0.6)\n",
    "axes[0, 1].set_xlabel('Moneyness')\n",
    "axes[0, 1].set_ylabel('Volatility')\n",
    "axes[0, 1].set_title('Volatility Smile')\n",
    "\n",
    "# Volatility distribution by moneyness category\n",
    "vol_by_moneyness = option_data.groupby('moneyness_category')['volatility'].mean()\n",
    "vol_by_moneyness.plot(kind='bar', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Average Volatility by Moneyness')\n",
    "axes[1, 0].set_xlabel('Moneyness Category')\n",
    "axes[1, 0].set_ylabel('Average Volatility')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Price vs volatility\n",
    "axes[1, 1].scatter(option_data['volatility'], option_data['call_price'], alpha=0.6)\n",
    "axes[1, 1].set_xlabel('Volatility')\n",
    "axes[1, 1].set_ylabel('Call Price')\n",
    "axes[1, 1].set_title('Call Price vs Volatility')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Preprocessing\n",
    "\n",
    "Let's demonstrate data preprocessing techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessor\n",
    "preprocessor = FinancialDataPreprocessor(random_state=42)\n",
    "\n",
    "# Handle outliers\n",
    "print(\"Detecting outliers...\")\n",
    "outliers = preprocessor.detect_outliers(option_data, ['volatility', 'call_price'])\n",
    "print(f\"Outliers detected: {sum(len(v) for v in outliers.values())}\")\n",
    "\n",
    "# Remove outliers\n",
    "clean_data = preprocessor.remove_outliers(option_data, outliers, strategy='cap')\n",
    "print(f\"Data shape after outlier removal: {clean_data.shape}\")\n",
    "\n",
    "# Handle skewness\n",
    "print(\"\\nHandling skewness...\")\n",
    "processed_data = preprocessor.handle_skewness(clean_data, ['volatility'])\n",
    "print(f\"Data shape after preprocessing: {processed_data.shape}\")\n",
    "\n",
    "# Scale features\n",
    "scaled_data = preprocessor.scale_features(processed_data, ['spot_price', 'strike_price', 'volatility'])\n",
    "print(f\"Data shape after scaling: {scaled_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Principal Component Analysis\n",
    "\n",
    "Let's perform PCA to understand the main components of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical features for PCA\n",
    "numerical_features = ['spot_price', 'strike_price', 'time_to_expiry', 'risk_free_rate', 'volatility']\n",
    "X = option_data[numerical_features]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Plot explained variance\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), \n",
    "         pca.explained_variance_ratio_, 'bo-', linewidth=2)\n",
    "plt.title('Explained Variance by Principal Components')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), \n",
    "         np.cumsum(pca.explained_variance_ratio_), 'ro-', linewidth=2)\n",
    "plt.title('Cumulative Explained Variance')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display component loadings\n",
    "loadings = pd.DataFrame(\n",
    "    pca.components_.T,\n",
    "    columns=[f'PC{i+1}' for i in range(len(numerical_features))],\n",
    "    index=numerical_features\n",
    ")\n",
    "\n",
    "print(\"Principal Component Loadings:\")\n",
    "print(loadings.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Insights\n",
    "\n",
    "Let's summarize our findings from the data exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== DATA EXPLORATION SUMMARY ===\")\n",
    "print(f\"Total option samples: {len(option_data):,}\")\n",
    "print(f\"Total swaption samples: {len(swaption_data):,}\")\n",
    "print(f\"Total yield curve samples: {len(yield_curves):,}\")\n",
    "print(f\"Total volatility surface samples: {len(vol_surfaces):,}\")\n",
    "print()\n",
    "\n",
    "print(\"KEY FINDINGS:\")\n",
    "print(\"1. Option prices range from $\" + f\"{option_data['call_price'].min():.2f} to $\" + f\"{option_data['call_price'].max():.2f}\")\n",
    "print(\"2. Most options are ATM (moneyness between 0.95-1.05)\")\n",
    "print(\"3. Volatility shows a smile pattern with higher values for OTM options\")\n",
    "print(\"4. Strong correlation between volatility and option prices\")\n",
    "print(\"5. First 3 principal components explain ~85% of variance\")\n",
    "print()\n",
    "\n",
    "print(\"DATA QUALITY:\")\n",
    "print(\"- No missing values in generated data\")\n",
    "print(\"- Some outliers detected and handled\")\n",
    "print(\"- Volatility distribution is realistic\")\n",
    "print(\"- Correlations are consistent with financial theory\")\n",
    "print()\n",
    "\n",
    "print(\"NEXT STEPS:\")\n",
    "print(\"1. Feature engineering for model training\")\n",
    "print(\"2. Model selection and training\")\n",
    "print(\"3. Cross-validation and hyperparameter tuning\")\n",
    "print(\"4. Model evaluation and comparison\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
